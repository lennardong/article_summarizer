<h1> Text-MiningGP12</h1>

These are the files and data used for generation. <br>

Do note the order to run the files and some of their dependencies.<br>
Depending on your current environment, there may be more packages required.<br>
Running of notebooks with the relevant folders are to be done on your machine locally. <br>

<h2>Dependencies</h2>
- seaborn <br>
- sentencepiece <br>
- textacy <br>
- en_core_web_lg <br>
- en_core_web_md <br>
- openai (and an api key for the code to work) <br>

<h2>Required folders</h2>
- data <br>
- models <br>
- results <br>
<br>

<h2>Notebook Sequence</h2>
<h3>EDA</h3>
- T5_00_EDA_LO.ipynb (used for EDA of WebNLG Triplet Format) <br>

<h3>For Text Preprocessing </h3>
- covar_00_bbcBatch_LO.ipynb (used to batch preprocess documents, replace text with covariance resolution) <br>
- triplets_01_clean_LO.ipynb (triple generation, greedy) <br>
- triplets_02_tripleFormatting_LO.ipynb (triple generation, strict) <br>
<br>
<h3>For LLM Fine Tuning </h3>
All these are Kaggle notebooks <br>
- GPT_00_fineTuning.ipynb <br>
- T5_01_train8epoch.ipynb <br>
- T5_01_train16epoch.ipynb <br>
<br>
<h3>For Text Generation </h3>
All export to a folder called “results” <br>
- GPT_01_textGenDistil_LO.ipynb <br>
- GPT_01_textGenDistilFiltered_LO.ipynb <br>
- GPT_01_textGenGPT2med_LO.ipynb <br>
- ChatGPT_01_promptedTextGen.ipynb <br>
- T5_02_textGen8epoch.ipynb <br>
- T5_02_textGen16Epoch_LO.ipynb <br>
<br>
<h3>For Evaluation </h3>
- scoring_BatchSimplicityIndex_LO.ipynb <br>
- util_simplicityIndex.py (this is imported into other notebooks)  <br>
